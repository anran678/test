""" Train for generating LIIF, from image to implicit representation.

    Config:
        train_dataset:
          dataset: $spec; wrapper: $spec; batch_size:
        val_dataset:
          dataset: $spec; wrapper: $spec; batch_size:
        (data_norm):
            inp: {sub: []; div: []}
            gt: {sub: []; div: []}
        (eval_type):
        (eval_bsize):

        model: $spec
        optimizer: $spec
        epoch_max:
        (multi_step_lr):
            milestones: []; gamma: 0.5
        (resume): *.pth

        (epoch_val): ; (epoch_save):
"""

import argparse
import os

import yaml
import torch
import torch.nn as nn
from tqdm import tqdm
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import MultiStepLR

import numpy as np

import datasets
import models
import utils
from test import eval_psnr
from torchprofile import profile_macs
import time

from utils import make_coord

def calculate_flops_and_params(model, input_size):
    # 创建输入张量
    input_tensor = torch.randn(*input_size).cuda()

    # 计算参数量
    total_params = sum(p.numel() for p in model.parameters())
    
    h_hr = input_size[-2]*4
    w_hr = input_size[-1]*4
    coord = make_coord([h_hr, w_hr], flatten=True).cuda()
    coord = coord.unsqueeze(0)
    cell = torch.ones_like(coord).cuda() # torch.tensor([2 / h_hr, 2 / w_hr], dtype=torch.float32).unsqueeze(0)
    
    # 计算 FLOPS
    macs = profile_macs(model, args=(input_tensor, coord, cell))
    flops = 2 * macs  # 每个 MAC 约等于 2 FLOPS

    return flops, total_params

def convert(value):
    if value >= 1e9:
        return f"{value / 1e9:.2f}G"
    elif value >= 1e6:
        return f"{value / 1e6:.2f}M"
    elif value >= 1e3:
        return f"{value / 1e3:.2f}K"
    else:
        return f"{value:.2f}"


def prepare_training():
    if config.get('resume') is not None:
        sv_file = torch.load(config['resume'])
        model = models.make(sv_file['model'], load_sd=True).cuda()
        optimizer = utils.make_optimizer(
            model.parameters(), sv_file['optimizer'], load_sd=True)
        epoch_start = sv_file['epoch'] + 1
        if config.get('multi_step_lr') is None:
            lr_scheduler = None
        else:
            lr_scheduler = MultiStepLR(optimizer, **config['multi_step_lr'])
        for _ in range(epoch_start - 1):
            lr_scheduler.step()
    else:
        model = models.make(config['model']).cuda()
        optimizer = utils.make_optimizer(
            model.parameters(), config['optimizer'])
        epoch_start = 1
        if config.get('multi_step_lr') is None:
            lr_scheduler = None
        else:
            lr_scheduler = MultiStepLR(optimizer, **config['multi_step_lr'])

    log('model: #params={}'.format(utils.compute_num_params(model, text=True)))
    return model, optimizer, epoch_start, lr_scheduler




def main(config_, save_path):
    global config, log, writer
    config = config_
    log, writer = utils.set_save_path(save_path)
    with open(os.path.join(save_path, 'config.yaml'), 'w') as f:
        yaml.dump(config, f, sort_keys=False)

    
    model, optimizer, epoch_start, lr_scheduler = prepare_training()

    n_gpus = len(os.environ['CUDA_VISIBLE_DEVICES'].split(','))
    ''''if n_gpus > 1:
        model = nn.parallel.DataParallel(model)'''


    timer = utils.Timer()


    model, optimizer, epoch_start, lr_scheduler = prepare_training()

    n_gpus = len(os.environ['CUDA_VISIBLE_DEVICES'].split(','))

    epoch_max = config['epoch_max']
    epoch_val = config.get('epoch_val')
    epoch_save = config.get('epoch_save')
    max_val_v = -1e18

    input_size = (1, 3, 48, 48)
    
    '''macs_encoder = profile_macs(model.encoder, args=(torch.randn(*(1,3,48,48)).cuda()))
    flops = 2 * macs_encoder
    params = sum(p.numel() for p in model.encoder.parameters())
    print(f"FLOPS: {convert(flops)}FLOPS")
    print(f"Total Params: {convert(params)}Params")'''
    
    
    # 计算 FLOPS 和参数量
    flops, params = calculate_flops_and_params(model, input_size)
    print(f"FLOPS: {flops}")
    print(f"Parameters: {params}")
    print(f"FLOPS: {convert(flops)}FLOPS")
    print(f"Total Params: {convert(params)}Params")
    
    input_size = (1, 3, 48, 48)
    inp = torch.randn(*input_size).cuda()
    # scale = torch.tensor([4]).cuda()
    
    times = []
    for scale in np.arange(4.0, 6.01, 0.01): #[4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9,5,5.1,5.2,5.3,5.4,5.5,5.6,5.7,5.8,5.9,6]:
        print(scale)
        h_hr = input_size[-2]*scale
        w_hr = input_size[-1]*scale
        coord = make_coord([h_hr, w_hr], flatten=True).cuda()
        coord = coord.unsqueeze(0)
        cell = torch.ones_like(coord).cuda()

        for i in range(10):
            pred = model(inp, coord, cell)

        start_time = time.time()  # 获取开始时间

        for i in range(100):
            pred = model(inp, coord, cell)

        end_time = time.time()  # 获取结束时间
        elapsed_time = end_time - start_time 
        times.append(elapsed_time)
    
    total_time = sum(times)
    print(f"Total time: {total_time*10} ms")
        
    
    '''h_hr = input_size[-2]*scale
    w_hr = input_size[-1]*scale
    coord = make_coord([h_hr, w_hr], flatten=True).cuda()
    coord = coord.unsqueeze(0)
    cell = torch.ones_like(coord).cuda()
    
    for i in range(10):
        pred = model(inp, coord, cell)
    
    start_time = time.time()  # 获取开始时间

    for i in range(100):
        pred = model(inp, coord, cell)

    end_time = time.time()  # 获取结束时间

    print(f"running time: {(end_time - start_time)*10} ms")'''


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', default='/code/liif-main/configs/train-div2k/train_edsr-baseline-liif.yaml')
    parser.add_argument('--name', default='/output/experiment/')
    parser.add_argument('--tag', default=None)
    parser.add_argument('--gpu', default='0')
    args = parser.parse_args()

    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu

    with open(args.config, 'r') as f:
        config = yaml.load(f, Loader=yaml.FullLoader)
        print('config loaded.')

    save_name = args.name
    if save_name is None:
        save_name = '_' + args.config.split('/')[-1][:-len('.yaml')]
    if args.tag is not None:
        save_name += '_' + args.tag
    save_path = os.path.join('./save', save_name)
    
    print(save_path)

    main(config, save_path)
